{"Title": "Negotiating team formation using deep reinforcement learning", "Year": 2020, "Source": "Artif Intell", "Volume": "288", "Issue": null, "Art.No": null, "PageStart": null, "PageEnd": null, "CitedBy": 0, "DOI": "10.1016/j.artint.2020.103356", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85088924222&origin=inward", "Abstract": "\u00a9 2020 Elsevier B.V.When autonomous agents interact in the same environment, they must often cooperate to achieve their goals. One way for agents to cooperate effectively is to form a team, make a binding agreement on a joint plan, and execute it. However, when agents are self-interested, the gains from team formation must be allocated appropriately to incentivize agreement. Various approaches for multi-agent negotiation have been proposed, but typically only work for particular negotiation protocols. More general methods usually require human input or domain-specific data, and so do not scale. To address this, we propose a framework for training agents to negotiate and form teams using deep reinforcement learning. Importantly, our method makes no assumptions about the specific negotiation protocol, and is instead completely experience driven. We evaluate our approach on both non-spatial and spatially extended team-formation negotiation environments, demonstrating that our agents beat hand-crafted bots and reach negotiation outcomes consistent with fair solutions predicted by cooperative game theory. Additionally, we investigate how the physical location of agents influences negotiation outcomes.", "AuthorKeywords": ["Coalition formation", "Cooperative games", "Deep learning", "Multi-agent systems", "Reinforcement learning", "Shapley value", "Team formation"], "IndexKeywords": ["Cooperative game theory", "Domain specific", "General method", "Multiagent negotiation", "Negotiation outcomes", "Negotiation protocol", "Physical locations", "Team formation"], "DocumentType": "Journal", "PublicationStage": null, "OpenAccess": 2, "EID": "2-s2.0-85088924222", "SubjectAreas": [["Language and Linguistics", "ARTS", "1203"], ["Linguistics and Language", "SOCI", "3310"], ["Artificial Intelligence", "COMP", "1702"]], "AuthorData": {"15130847200": {"Name": "Bachrach Y.", "AuthorID": "15130847200", "AffiliationID": "60111161", "AffiliationName": "DeepMind"}, "57212169498": {"Name": "Everett R.", "AuthorID": "57212169498", "AffiliationID": "60111161", "AffiliationName": "DeepMind"}, "57208443684": {"Name": "Hughes E.", "AuthorID": "57208443684", "AffiliationID": "60111161", "AffiliationName": "DeepMind"}, "55274442200": {"Name": "Lazaridou A.", "AuthorID": "55274442200", "AffiliationID": "60111161", "AffiliationName": "DeepMind"}, "57204365471": {"Name": "Leibo J.Z.", "AuthorID": "57204365471", "AffiliationID": "60111161", "AffiliationName": "DeepMind"}, "56522887100": {"Name": "Lanctot M.", "AuthorID": "56522887100", "AffiliationID": "60111161", "AffiliationName": "DeepMind"}, "15727636000": {"Name": "Johanson M.", "AuthorID": "15727636000", "AffiliationID": "60111161", "AffiliationName": "DeepMind"}, "55217611900": {"Name": "Czarnecki W.M.", "AuthorID": "55217611900", "AffiliationID": "60111161", "AffiliationName": "DeepMind"}, "6601966753": {"Name": "Graepel T.", "AuthorID": "6601966753", "AffiliationID": "60111161", "AffiliationName": "DeepMind"}}}