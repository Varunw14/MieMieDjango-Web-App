{"Title": "3-D Passive-Vision-Aided Pedestrian Dead Reckoning for Indoor Positioning", "Year": 2020, "Source": "IEEE Trans. Instrum. Meas.", "Volume": "69", "Issue": 4, "Art.No": null, "PageStart": 1370, "PageEnd": 1386, "CitedBy": 6, "DOI": "10.1109/TIM.2019.2910923", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85075466882&origin=inward", "Abstract": "\u00a9 1963-2012 IEEE.The vision-aided pedestrian dead reckoning (PDR) systems have become increasingly popular, thanks to the ubiquitous mobile phone embedded with several sensors. This is particularly important for indoor use, where other indoor positioning technologies require additional installation or body attachment of specific sensors. This paper proposes and develops a novel 3-D passive vision-aided PDR system that uses multiple surveillance cameras and smartphone-based PDR. The proposed system can continuously track users' movement on different floors by integrating results of inertial navigation and Faster Region-Based Convolutional Neutral Network (Faster R-CNN)-based real-time pedestrian detection, while utilizing existing camera locations and embedded barometers to provide floor/height information to identify user positions in 3-D space. This novel system provides a relatively low-cost and user-friendly solution, which requires no modifications to currently available mobile devices and also the existing indoor infrastructures at many public buildings for the purpose of 3-D indoor positioning. This paper shows the case of testing the prototype in a four-floor building, where it can provide the horizontal accuracy of 0.16 m and the vertical accuracy of 0.5 m. This level of accuracy is even better than required accuracy targeted by several emergency services, including the Federal Communications Commission (FCC). This system is developed for both Android and iOS-running devices.", "AuthorKeywords": ["Altimetry", "identification of persons", "image processing", "indoor environments", "inertial navigation", "position measurement", "sensor fusion"], "IndexKeywords": ["Altimetry", "Identification of persons", "Indoor environment", "Inertial navigations", "Sensor fusion"], "DocumentType": "Journal", "PublicationStage": null, "OpenAccess": 2, "EID": "2-s2.0-85075466882", "SubjectAreas": [["Instrumentation", "PHYS", "3105"], ["Electrical and Electronic Engineering", "ENGI", "2208"]], "AuthorData": {"57203152001": {"Name": "Yan J.", "AuthorID": "57203152001", "AffiliationID": "60104720", "AffiliationName": "International Doctoral Innovation Centre, University of Nottingham"}, "57203156837": {"Name": "He G.", "AuthorID": "57203156837", "AffiliationID": "60104720", "AffiliationName": "Department of Geographical Science, University of Nottingham"}, "55626206500": {"Name": "Basiri A.", "AuthorID": "55626206500", "AffiliationID": "60022148", "AffiliationName": "Centre for Advanced Analysis, University College London"}, "36898196900": {"Name": "Hancock C.", "AuthorID": "36898196900", "AffiliationID": "60104720", "AffiliationName": "Department of Civil Engineering, University of Nottingham"}}}