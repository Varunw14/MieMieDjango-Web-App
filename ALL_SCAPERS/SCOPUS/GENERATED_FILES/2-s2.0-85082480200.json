{"Title": "Detecting errors in pick and place procedures", "Year": 2020, "Source": "Int Conf Intell User Interfaces Proc IUI", "Volume": null, "Issue": null, "Art.No": null, "PageStart": 536, "PageEnd": 545, "CitedBy": 2, "DOI": "10.1145/3377325.3377497", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85082480200&origin=inward", "Abstract": "\u00a9 ACM.Many human activities, such as manufacturing and assembly, are sequence-constrained procedural tasks (SPTs): they consist of a series of steps that must be executed in a specific spatial/temporal order. However, these tasks can be error prone - steps can be missed out, executed out-of-order, and repeated. The ability to automatically predict if a person is about to commit an error could greatly help in these cases. The prediction could be used, for example, to provide feedback to prevent mistakes or mitigate their effects. In this paper, we present a novel approach for real-time error prediction for multi-step sequence tasks which uses a minimum viable set of behavioural signals. We have three main contributions. The first we present an architecture for real-time error prediction based on task tracking and intent prediction. The second is to explore the effectiveness of using hand position and eye-gaze tracking for task tracking. We confirm that eye-gaze is more effective for intent prediction, hand tracking is more accurate for task tracking and that combining the two provides the best overall response. We show that using Hands and Gaze tracking data we can predict selection/placement errors with an F1 score of 97%, approximately 300ms before the error would occur. Finally, we discuss the application of this hand-gaze error detection architecture used in conjunction with head-mounted AR displays, to support industrial manual assembly.", "AuthorKeywords": ["error prediction", "human-centered design", "intelligent assistive systems", "long-short term memory", "manual assembly procedures", "user intent prediction"], "IndexKeywords": ["Assistive system", "Error prediction", "Eye gaze tracking", "Hand positions", "Human activities", "Human-centered designs", "Manual assembly", "Real time errors"], "DocumentType": "Conference Proceeding", "PublicationStage": null, "OpenAccess": 2, "EID": "2-s2.0-85082480200", "SubjectAreas": [["Software", "COMP", "1712"], ["Human-Computer Interaction", "COMP", "1709"]], "AuthorData": {"57204780702": {"Name": "Bovo R.", "AuthorID": "57204780702", "AffiliationID": "60015150", "AffiliationName": "Imperial College London"}, "56380384400": {"Name": "Binetti N.", "AuthorID": "56380384400", "AffiliationID": "60015150", "AffiliationName": "Imperial College London"}, "22833443900": {"Name": "Brumby D.P.", "AuthorID": "22833443900", "AffiliationID": "60015150", "AffiliationName": "Imperial College London"}, "7003972937": {"Name": "Julier S.", "AuthorID": "7003972937", "AffiliationID": "60015150", "AffiliationName": "Imperial College London"}}}