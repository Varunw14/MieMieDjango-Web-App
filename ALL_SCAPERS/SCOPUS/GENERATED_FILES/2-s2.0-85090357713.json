{"Title": "Emulated haptic shared control for brain-computer interfaces improves human-robot cooperation", "Year": 2020, "Source": "Proc. IEEE Int. Conf. Hum.-Mach. Syst., ICHMS", "Volume": null, "Issue": null, "Art.No": null, "PageStart": null, "PageEnd": null, "CitedBy": 1, "DOI": "10.1109/ICHMS49158.2020.9209521", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85090357713&origin=inward", "Abstract": "\u00a9 2020 IEEE.Today, technology provides many ways for humans to exchange their points of view about pretty much everything. Visual, audio and tactile media are most commonly used by humans, and they support communication in such a natural way that we don't even actively think about using them. But what about people who have lost motor or sensory capabilities for whom it is difficult or impossible to control or perceive the output of such technologies? In this case, perhaps the only way to communicate might be to use brain signals directly. The goal of this study is therefore towards providing people with tetraplegia, who may be confined to their room or bed, with a telepresence tool that facilitates the daily interactions so many of us take for granted. In our case, the telepresence tool is a robot that is remotely controlled. It can act as a medium for the user in their everyday life with the design of a virtual link with friends and relatives located in remote rooms or places or with different environments to explore. Therefore, the objective is to design a Human-Machine System that enables the control of a robot using thoughts alone. The technological part is composed of a brain-computer interface and a visual interface to implement an 'emulated haptic shared control' of the robot. Shared motion control is implemented between the user and the robot as well as an adaptive function allocation to manage the difficulty of the situation. The control schema that exploits this 'emulated haptic feedback' has been designed and evaluated using a Human-Machine Cooperation framework and the benefit of this type of interaction has been evaluated with five participants. Initial results indicate better control and cooperation with the 'emulated haptic feedback' than without.", "AuthorKeywords": ["adaptive level of automation", "brain-computer interface", "disability", "human-machine cooperation"], "IndexKeywords": ["Adaptive functions", "Control schema", "Haptic feedbacks", "Human-machine cooperation", "Human-robot cooperation", "Shared control", "Technological parts", "Visual Interface"], "DocumentType": "Conference Proceeding", "PublicationStage": null, "OpenAccess": 2, "EID": "2-s2.0-85090357713", "SubjectAreas": [["Human-Computer Interaction", "COMP", "1709"]], "AuthorData": {"15826687500": {"Name": "Pacaux-Lemoine M.P.", "AuthorID": "15826687500", "AffiliationID": "60027663, 60193405", "AffiliationName": "Universite Polytechnique Hauts-de-France, Umr Cnrs 8201 Lamih"}, "57193681139": {"Name": "Habib L.", "AuthorID": "57193681139", "AffiliationID": "60027663, 60193405", "AffiliationName": "Universite Polytechnique Hauts-de-France, Umr Cnrs 8201 Lamih"}, "57220273768": {"Name": "Sciacca N.", "AuthorID": "57220273768", "AffiliationID": "60022148, 60024067, 60099424", "AffiliationName": "University College London Rnoh, Aspire Create"}, "56295883500": {"Name": "Carlson T.", "AuthorID": "56295883500", "AffiliationID": "60022148, 60024067, 60099424", "AffiliationName": "University College London Rnoh, Aspire Create"}}}