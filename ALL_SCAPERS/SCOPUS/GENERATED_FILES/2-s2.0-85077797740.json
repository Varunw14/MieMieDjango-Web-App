{"Title": "Altering body perception and emotion in physically inactive people through movement sonification", "Year": 2019, "Source": "Int. Conf. Affect. Comput. Intell. Interact., ACII", "Volume": null, "Issue": null, "Art.No": null, "PageStart": 459, "PageEnd": 495, "CitedBy": 0, "DOI": "10.1109/ACII.2019.8925432", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85077797740&origin=inward", "Abstract": "\u00a9 2019 IEEE.Physical inactivity is an increasing problem. It has been linked to psychological and emotional barriers related to the perception of one's body, such as physical capabilities. It remains a challenge to design technologies to increase physical activity in inactive people. We propose the use of a sound interactive system where inputs from movement sensors integrated in shoes are transformed into sounds that evoke body sensations at a metaphorical level. Our user study investigates the effects of various gesture-sound mappings on the perception of one's body and its movement qualities (e.g. being flexible or agile), the related emotional state and movement patterns, when people performed two exercises, walking and thigh stretch. The results confirm the effect of the 'metaphor' conditions vs. the control conditions in feelings of body weight; feeling less tired and more in control; or being more comfortable, motivated, and happier. These changes linked to changes in affective state and body movement. We discuss the results in terms of how acting upon body perception and affective states through sensory feedback may in turn enhance physical activity, and the opportunities opened by our findings for the design of wearable technologies and interventions in inactive populations.", "AuthorKeywords": ["Body perception", "Emotion", "Multisensory feedback", "Physical activity", "Self-care technologies", "Sonification", "Wearables"], "IndexKeywords": ["Body perceptions", "Emotion", "Multi-sensory feedback", "Physical activity", "Self-care", "Sonifications", "Wearables"], "DocumentType": "Conference Proceeding", "PublicationStage": null, "OpenAccess": 2, "EID": "2-s2.0-85077797740", "SubjectAreas": [["Computer Networks and Communications", "COMP", "1705"], ["Human-Computer Interaction", "COMP", "1709"], ["Behavioral Neuroscience", "NEUR", "2802"], ["Social Psychology", "PSYC", "3207"]], "AuthorData": {"57202767077": {"Name": "Ley-Flores J.", "AuthorID": "57202767077", "AffiliationID": "60001741, 60086940", "AffiliationName": "DEI Interactive Systems Group, Universidad Carlos III de Madrid, U. Loyola Andaluc\u00eda, Department of Psychology"}, "57204340555": {"Name": "Bevilacqua F.", "AuthorID": "57204340555", "AffiliationID": "60013528", "AffiliationName": "Science Technology for Music and Sound, IRCAM"}, "6602671345": {"Name": "Bianchi-Berthouze N.", "AuthorID": "6602671345", "AffiliationID": "60022148", "AffiliationName": "UCL Interaction Centre, University College London"}, "57192782261": {"Name": "Taiadura-Jimenez A.", "AuthorID": "57192782261", "AffiliationID": "60001741", "AffiliationName": "DEI Interactive Systems Group, Universidad Carlos III de Madrid"}}}