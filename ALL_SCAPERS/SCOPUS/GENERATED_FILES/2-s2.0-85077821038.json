{"Title": "Learning over categorical data using counting features with an application on click-through rate estimation", "Year": 2019, "Source": "Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.", "Volume": null, "Issue": null, "Art.No": null, "PageStart": null, "PageEnd": null, "CitedBy": 0, "DOI": "10.1145/3326937.3341260", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85077821038&origin=inward", "Abstract": "\u00a9 2019 Association for Computing Machinery.Input data for many machine learning applications are often categorical and contain multiple fields. A common feature representation for such categorical data is one-hot encoding, which expresses data instances as high-dimensional sparse binary vectors. Given this encoding machine learning models, such as logistic regression or boosted trees, are trained. However, the following problems occur when dealing with large-scale data sets: (i) The binary feature space is sparse yet extremely large, which can require a large amount of computational resources. (ii) Models based on such a feature representation will typically need to be re-trained in order to keep up-to-date with any changes in the data distribution. (iii) The one-hot feature representation provides little generalisation ability. In this paper, we propose counting features, a novel statisticsbased feature engineering paradigm, to address the above problems. Mathematically, we show a deterministic relationship between the optimal regression parameters of counting features and one-hot binary features. Then, in the context of click-through rate estimation in online advertising, we demonstrate that counting features indeed bring better generalisation ability. Our experiments on real-world large-scale datasets demonstrate that, despite their compressed nature, the proposed counting feature engineering outperforms the one-hot binary encoded features in various cases such as cold start training and cross-campaigns training.", "AuthorKeywords": null, "IndexKeywords": ["Computational resources", "Feature engineerings", "Feature representation", "Large-scale datasets", "Logistic regressions", "Machine learning applications", "Machine learning models", "Regression parameters"], "DocumentType": "Conference Proceeding", "PublicationStage": null, "OpenAccess": 0, "EID": "2-s2.0-85077821038", "SubjectAreas": [["Software", "COMP", "1712"], ["Information Systems", "COMP", "1710"]], "AuthorData": {"57148845300": {"Name": "Wu X.", "AuthorID": "57148845300", "AffiliationID": "60022148", "AffiliationName": "University College London"}, "57204819270": {"Name": "Luo R.", "AuthorID": "57204819270", "AffiliationID": "60022148", "AffiliationName": "University College London"}, "55902731900": {"Name": "Wang J.", "AuthorID": "55902731900", "AffiliationID": "60022148", "AffiliationName": "University College London"}, "57213518153": {"Name": "Gao X.", "AuthorID": "57213518153", "AffiliationID": "112634951", "AffiliationName": "JPMorgan London"}, "56108513500": {"Name": "Zhang W.", "AuthorID": "56108513500", "AffiliationID": "60025084", "AffiliationName": "Shanghai Jiao Tong University"}}}