{"Title": "Randomized learning and generalization of fair and private classifiers: From PAC-Bayes to stability and differential privacy", "Year": 2020, "Source": "Neurocomputing", "Volume": "416", "Issue": null, "Art.No": null, "PageStart": 231, "PageEnd": 243, "CitedBy": 0, "DOI": "10.1016/j.neucom.2019.12.137", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85083696087&origin=inward", "Abstract": "\u00a9 2020 Elsevier B.V.We address the problem of randomized learning and generalization of fair and private classifiers. From one side we want to ensure that sensitive information does not unfairly influence the outcome of a classifier. From the other side we have to learn from data while preserving the privacy of individual observations. We initially face this issue in the PAC-Bayes framework presenting an approach which trades off and bounds the risk and the fairness of the randomized (Gibbs) classifier. Our new approach is able to handle several different state-of-the-art fairness measures. For this purpose, we further develop the idea that the PAC-Bayes prior can be defined based on the data-generating distribution without actually knowing it. In particular, we define a prior and a posterior which give more weight to functions with good generalization and fairness properties. Furthermore, we will show that this randomized classifier possesses interesting stability properties using the algorithmic distribution stability theory. Finally, we will show that the new posterior can be exploited to define a randomized accurate and fair algorithm. Differential privacy theory will allow us to derive that the latter algorithm has interesting privacy preserving properties ensuring our threefold goal of good generalization, fairness, and privacy of the final model.", "AuthorKeywords": ["Algorithmic (distribution) stability", "Algorithmic fairness", "Differential privacy", "Generalization", "PAC-Bayes", "Privacy preserving data analysis", "Randomized algorithm", "Randomized classifier"], "IndexKeywords": ["Differential privacies", "Fairness measures", "Fairness properties", "Privacy preserving", "Sensitive informations", "Stability properties", "Stability theories", "State of the art"], "DocumentType": "Journal", "PublicationStage": null, "OpenAccess": 0, "EID": "2-s2.0-85083696087", "SubjectAreas": [["Computer Science Applications", "COMP", "1706"], ["Cognitive Neuroscience", "NEUR", "2805"], ["Artificial Intelligence", "COMP", "1702"]], "AuthorData": {"41262130900": {"Name": "Oneto L.", "AuthorID": "41262130900", "AffiliationID": "60028868", "AffiliationName": "University of Pisa"}, "55977393100": {"Name": "Donini M.", "AuthorID": "55977393100", "AffiliationID": "60076757", "AffiliationName": "Amazon"}, "6603887035": {"Name": "Pontil M.", "AuthorID": "6603887035", "AffiliationID": "60022148", "AffiliationName": "University College London"}, "7003290763": {"Name": "Shawe-Taylor J.", "AuthorID": "7003290763", "AffiliationID": "60022148", "AffiliationName": "University College London"}}}