{"Title": "Primary auditory cortex representation of fear-conditioned musical sounds", "Year": 2020, "Source": "Hum. Brain Mapp.", "Volume": "41", "Issue": 4, "Art.No": null, "PageStart": 882, "PageEnd": 891, "CitedBy": 0, "DOI": "10.1002/hbm.24846", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85074793893&origin=inward", "Abstract": "\u00a9 2019 The Authors. Human Brain Mapping published by Wiley Periodicals, Inc.Auditory cortex is required for discriminative fear conditioning beyond the classical amygdala microcircuit, but its precise role is unknown. It has previously been suggested that Heschl's gyrus, which includes primary auditory cortex (A1), but also other auditory areas, encodes threat predictions during presentation of conditioned stimuli (CS) consisting of monophones, or frequency sweeps. The latter resemble natural prosody and contain discriminative spectro-temporal information. Here, we use functional magnetic resonance imaging (fMRI) in humans to address CS encoding in A1 for stimuli that contain only spectral but no temporal discriminative information. Two musical chords (complex) or two monophone tones (simple) were presented in a signaled reinforcement context (reinforced CS+ and nonreinforced CS\u2212), or in a different context without reinforcement (neutral sounds, NS1 and NS2), with an incidental sound detection task. CS/US association encoding was quantified by the increased discriminability of BOLD patterns evoked by CS+/CS\u2212, compared to NS pairs with similar physical stimulus differences and task demands. A1 was defined on a single-participant level and based on individual anatomy. We find that in A1, discriminability of CS+/CS\u2212 was higher than for NS1/NS2. This representation of unconditioned stimulus (US) prediction was of comparable magnitude for both types of sounds. We did not observe such encoding outside A1. Different from frequency sweeps investigated previously, musical chords did not share representations of US prediction with monophone sounds. To summarize, our findings suggest decodable representation of US predictions in A1, for various types of CS, including musical chords that contain no temporal discriminative information.", "AuthorKeywords": ["associative learning", "discriminative fear conditioning", "emotional learning", "multivariate pattern analysis", "spectrotemporal information", "threat conditioning", "threat representation"], "IndexKeywords": null, "DocumentType": "Journal", "PublicationStage": null, "OpenAccess": 1, "EID": "2-s2.0-85074793893", "SubjectAreas": [["Anatomy", "MEDI", "2702"], ["Radiological and Ultrasound Technology", "HEAL", "3614"], ["Radiology, Nuclear Medicine and Imaging", "MEDI", "2741"], ["Neurology", "NEUR", "2808"], ["Neurology (clinical)", "MEDI", "2728"]], "AuthorData": {"56611973300": {"Name": "Staib M.", "AuthorID": "56611973300", "AffiliationID": "60012614", "AffiliationName": "Neuroscience Center Zurich, 8057 University of Zurich"}, "57194202250": {"Name": "Abivardi A.", "AuthorID": "57194202250", "AffiliationID": "60012614", "AffiliationName": "Neuroscience Center Zurich, 8057 University of Zurich"}, "9746516300": {"Name": "Bach D.", "AuthorID": "9746516300", "AffiliationID": "60022148, 60084279", "AffiliationName": "Wellcome Centre for Human Neuroimaging, University College London"}}}