{"Title": "Fully hardware-implemented memristor convolutional neural network", "Year": 2020, "Source": "Nature", "Volume": "577", "Issue": 7792, "Art.No": null, "PageStart": 641, "PageEnd": 646, "CitedBy": 88, "DOI": "10.1038/s41586-020-1942-4", "Link": "https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85078690243&origin=inward", "Abstract": "\u00a9 2020, The Author(s), under exclusive licence to Springer Nature Limited.Memristor-enabled neuromorphic computing systems provide a fast and energy-efficient approach to training neural networks1\u20134. However, convolutional neural networks (CNNs)\u2014one of the most important models for image recognition5\u2014have not yet been fully hardware-implemented using memristor crossbars, which are cross-point arrays with a memristor device at each intersection. Moreover, achieving software-comparable results is highly challenging owing to the poor yield, large variation and other non-ideal characteristics of devices6\u20139. Here we report the fabrication of high-yield, high-performance and uniform memristor crossbar arrays for the implementation of CNNs, which integrate eight 2,048-cell memristor arrays to improve parallel-computing efficiency. In addition, we propose an effective hybrid-training method to adapt to device imperfections and improve the overall system performance. We built a five-layer memristor-based CNN to perform MNIST10 image recognition, and achieved a high accuracy of more than 96 per cent. In addition to parallel convolutions using different kernels with shared inputs, replication of multiple identical kernels in memristor arrays was demonstrated for processing different inputs in parallel. The memristor-based CNN neuromorphic system has an energy efficiency more than two orders of magnitude greater than that of state-of-the-art graphics-processing units, and is shown to be scalable to larger networks, such as residual neural networks. Our results are expected to enable a viable memristor-based non-von Neumann hardware solution for deep neural networks and edge computing.", "AuthorKeywords": null, "IndexKeywords": null, "DocumentType": "Journal", "PublicationStage": null, "OpenAccess": 0, "EID": "2-s2.0-85078690243", "SubjectAreas": [["Multidisciplinary", "MULT", "1000"]], "AuthorData": {"57190174635": {"Name": "Yao P.", "AuthorID": "57190174635", "AffiliationID": "60025278", "AffiliationName": "Institute of Microelectronics, Beijing Innovation Center for Future Chips (ICFC), Tsinghua University"}, "55649971900": {"Name": "Wu H.", "AuthorID": "55649971900", "AffiliationID": "60025278, 60073474", "AffiliationName": "Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University"}, "55707310000": {"Name": "Gao B.", "AuthorID": "55707310000", "AffiliationID": "60025278, 60073474", "AffiliationName": "Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University"}, "35789210900": {"Name": "Tang J.", "AuthorID": "35789210900", "AffiliationID": "60025278, 60073474", "AffiliationName": "Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University"}, "57194219666": {"Name": "Zhang Q.", "AuthorID": "57194219666", "AffiliationID": "60025278", "AffiliationName": "Institute of Microelectronics, Beijing Innovation Center for Future Chips (ICFC), Tsinghua University"}, "57194220166": {"Name": "Zhang W.", "AuthorID": "57194220166", "AffiliationID": "60025278", "AffiliationName": "Institute of Microelectronics, Beijing Innovation Center for Future Chips (ICFC), Tsinghua University"}, "57207182359": {"Name": "Qian H.", "AuthorID": "57207182359", "AffiliationID": "60025278, 60073474", "AffiliationName": "Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University"}, "10046237000": {"Name": "Yang J.J.", "AuthorID": "10046237000", "AffiliationID": "60014313", "AffiliationName": "Department of Electrical and Computer Engineering, University of Massachusetts"}}}